{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d69f81f0",
   "metadata": {},
   "source": [
    "# Pandas\n",
    "\n",
    "Pandas is one of the most essential Python libraries, especially when working with tabular data. Pandas simplifies data curation, manipulation, and visualization of data considerably. In this notebook, you can find an introduction to using Pandas in data science projects.\n",
    "\n",
    "<u>**Outline:**</u>\n",
    "1. [Importing the Pandas library](#1)\n",
    "2. [Importing data](#2)\n",
    "    1. [Loading Excel or csv files](#2.1)\n",
    "    2. [Accessing APIs](#2.2)\n",
    "3. [Pandas Series](#3) **[(TASK I)](#task1)**\n",
    "4. [Pandas DataFrames](#4)\n",
    "    1. [Generating and accessing  Pandas DataFrames](#4.1) **[(TASK II)](#task2)**\n",
    "    2. [Operations on DataFrames](#4.2)\n",
    "        1. [Selecting data](#4.2.1)\n",
    "        2. [Slicing data frames](#4.2.2) \n",
    "           1. [Slicing by label with loc](#4.2.2.1)\n",
    "           2. [Slicing by position with iloc](#4.2.2.2)\n",
    "        3. [Filtering](#4.2.3)\n",
    "        4. [Transposing, Sorting, and Grouping](#4.2.4)\n",
    "   **[(TASK III)](#task3)**\n",
    "5. [Advancing operations](#5)**[(TASK IV)](#task4)**\n",
    "6. [Profiling](#6)\n",
    "7. [Final Remarks](#7)\n",
    "\n",
    "<u>**References:**</u> \n",
    "- For the full Pandas documentation see https://pandas.pydata.org/docs/. \n",
    "- Pandas Getting Started Guide: https://pandas.pydata.org/docs/getting_started/index.html#getting-started.\n",
    "- A *cheat sheet* on data manipulation with Pandas: https://pandas.pydata.org/Pandas_Cheat_Sheet.pdf.\n",
    "- For the basic basics of plotting with Pandas, see https://www.enthought.com/wp-content/uploads/2019/09/Enthought-Pandas-Cheat-Sheet-1-Plotting-with-Series-and-DataFrames-v1.0.2.pdf.\n",
    "- For more complete info on plotting with Pandas see https://pandas.pydata.org/docs/user_guide/visualization.html. \n",
    "\n",
    "<u>**Authors:**</u> \n",
    "- Julian Vicens: <julianvicens@ub.edu>\n",
    "- Franciska Peter\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc112ada",
   "metadata": {},
   "source": [
    "## 1. Importing the pandas library <a class=\"anchor\" id=\"1\"></a>\n",
    "Pandas is typically imported into the namespace pd, just as numpy is typically imported as np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea41433",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52662248",
   "metadata": {},
   "source": [
    "## 2. Importing data <a class=\"anchor\" id=\"2\"></a>\n",
    "Data can be imported either by loading files or by accessing an API (Application Programming Interface).\n",
    "\n",
    "### 2.1. Loading Excel or csv files <a class=\"anchor\" id=\"2.1\"></a>\n",
    "For instance with functions [read_excel](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_excel.html) or [read_csv](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.read_csv.html) tables are loaded from files into Pandas DataFrames.\n",
    "\n",
    "**Data extracted from:** Nelson AB, Faraguna U, Zoltan JT, Tononi G, Cirelli C. Sleep patterns and homeostatic mechanisms in adolescent mice. Brain Sci. 2013 Mar 19;3(1):318-43. doi: 10.3390/brainsci3010318. PMID: 23772316; PMCID: PMC3682503."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ad523-ae2d-4d0b-ad97-830db1ae7aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data directory\n",
    "data_dir = \"../data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7c03fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_xlsx = pd.read_excel(data_dir + \"Sleep_Patterns_and_Homeostatic_Mechanisms_in_Adolescent_Mice_2013.xlsx\",\n",
    "                         index_col=0,\n",
    "                         header=0)\n",
    "# show loaded table:\n",
    "mice_xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbc33fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mice_csv = pd.read_csv(data_dir + \"Sleep_Patterns_and_Homeostatic_Mechanisms_in_Adolescent_Mice_2013.csv\",\n",
    "                         index_col=0,\n",
    "                         header=0)\n",
    "# show loaded table:\n",
    "mice_csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035d281c",
   "metadata": {},
   "source": [
    "### 2.2. Accessing APIs <a class=\"anchor\" id=\"2.2\"></a>\n",
    "\n",
    "You will usually find a sample code for how to access an API on the webpage that publishes the open data. For our example, the open data provider [Portal de Dades Obertes de Catalunya](https://analisi.transparenciacatalunya.cat/) here for example the following [database](https://analisi.transparenciacatalunya.cat/Energia/Consum-d-energia-el-ctrica-per-municipis-i-sectors/8idm-becu) about energy consumption, requires the installation of [sodapy](https://github.com/xmunoz/sodapy) which has been installed with the requirements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b63e821d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sodapy import Socrata\n",
    "\n",
    "# Unauthenticated client only works with public data sets. Note 'None'\n",
    "# in place of application token, and no username or password:\n",
    "client = Socrata(\"analisi.transparenciacatalunya.cat\", None)\n",
    "\n",
    "# Example authenticated client (needed for non-public datasets):\n",
    "# client = Socrata(analisi.transparenciacatalunya.cat,\n",
    "#                  MyAppToken,\n",
    "#                  username=\"user@example.com\",\n",
    "#                  password=\"AFakePassword\")\n",
    "\n",
    "# First 2000 results, returned as JSON from API / converted to Python list of\n",
    "# dictionaries by sodapy.\n",
    "results = client.get(\"8idm-becu\", limit=2000)\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "consum_energia_df = pd.DataFrame.from_records(results)\n",
    "\n",
    "# show loaded table:\n",
    "consum_energia_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "996649fe",
   "metadata": {},
   "source": [
    "You see that they limit the downloaded lines to the first 2000 lines, but you can alter these numbers according to your needs. Acctually, if you register in their webpage they give you a TOKEN that allows you to access more lines in a quicker way. \n",
    "\n",
    "Note that on this particular database on energy consumption, you also find extensive information on who recorded the data when or what is the meaning of each column."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7190e63",
   "metadata": {},
   "source": [
    "## 3. Pandas Series <a class=\"anchor\" id=\"3\"></a>\n",
    "Above, we loaded **Pandas DataFrames** that represent tables. \n",
    "To begin with pandas, it is helpful to start with \"one-column tables\" that are represented by **Pandas Series**. For the full documentation of Pandas Series see https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.html."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab09b60",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Pandas Series of strings\n",
    "observed_birds = pd.Series([\"Wallcreeper\",\n",
    "                            \"Lammergeier\",\n",
    "                            \"Lammergeier\",\n",
    "                            \"Lammergeier\",\n",
    "                            \"Dupont's Lark\",\n",
    "                            \"Pin-tailed Sandgrouse\",\n",
    "                            \"Lammergeier\",\n",
    "                            \"Wallcreeper\",\n",
    "                            \"Little Bustard\",\n",
    "                            \"Dupont's Lark\",\n",
    "                            \"Wallcreeper\",\n",
    "                            \"Wallcreeper\",\n",
    "                            \"Citril Finch\",\n",
    "                            \"Black Wheatear\",\n",
    "                            \"Snowfinch\"\n",
    "                            ], \n",
    "                           dtype = str, # if you put nothing here, pandas inferres the type itself\n",
    "                           name = \"birds\"\n",
    "                          )\n",
    "\n",
    "# show Pandas series: \n",
    "observed_birds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a19cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of appearances of each bird, e.g. in a pie chart\n",
    "observed_birds.value_counts().plot.pie()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fe6d12a",
   "metadata": {},
   "source": [
    "Pandas Series can contain a variety of python data types, such as strings, integers, time stamps, and of course also floats. As an example, we'll draw N=10000 Gaussian random numbers and plot a histogram for them. Note that by loading pandas, we already loaded matplotlib.pyplot into namespace plt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55ad0005",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a Series of N Gaussian random numbers\n",
    "N = 10000\n",
    "sigma = 1\n",
    "mu = 2\n",
    "random_numbers_array = np.random.normal(mu, sigma, N)\n",
    "random_numbers = pd.Series(random_numbers_array)\n",
    "\n",
    "# Plot a normalized histogram\n",
    "ax = random_numbers.hist(density=True, bins=100)\n",
    "\n",
    "# Add the analytical Gaussian curve\n",
    "x = np.linspace(-1, 5, 200)\n",
    "ax.plot(x, np.exp(-(x - mu)**2 / (2 * sigma**2)) / (np.sqrt(2 * np.pi) * sigma))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c823b495",
   "metadata": {},
   "source": [
    "# TASK I: <a class=\"anchor\" id=\"task1\"></a>\n",
    "1. Label the x and y axes\n",
    "2. Change the colors of the bars and the line\n",
    "3. Give the plot a title\n",
    "4. Add a legend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04d1ac5-0c36-45fe-93ab-6e8a51d8b27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#### Code your solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20150726",
   "metadata": {},
   "source": [
    "In the following you see that simple numpy operations can directly be applied on Pandas Series (i.e. on columns of Data Frames). The output is again a pandas Series. \n",
    "\n",
    "Further, you'll see that you can transform print some basic statistics of pandas Series using pandas function *describe*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f8521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the absolute value of each item in the Pandas series and plot a histogram of the result\n",
    "ax = abs(random_numbers).hist(bins=10, density=True)\n",
    "\n",
    "# print some basic statistics of a Pandas series\n",
    "abs(random_numbers).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "668a7479",
   "metadata": {},
   "source": [
    "## 4. Pandas DataFrames <a class=\"anchor\" id=\"4\"></a>\n",
    "You find the full documentation here: https://pandas.pydata.org/pandas-docs/stable/reference/frame.html.\n",
    "\n",
    "### 4.1. Generating  and accessing Pandas DataFrames <a class=\"anchor\" id=\"4.1\"></a>\n",
    ".. and some manipulations.\n",
    "\n",
    "At first we see how to generate an empty data frame and fill it column by column. We see what's an index and what's a column. Then, we generate a data frame from a dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bbe225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There are plenty of different ways to create a DataFrame. \n",
    "\n",
    "# An empty DataFrame can be created by\n",
    "df = pd.DataFrame()  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1968ad5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This empty DataFrame can be filled columnwise with lists:\n",
    "\n",
    "# e.g.: add new column with name \"Country\" to data frame df\n",
    "df[\"Country\"]  = [\"UK\", \"France\", \"Spain\"]\n",
    "df[\"Capital\"] = [\"London\", \"Paris\", \"Madrid\"]\n",
    "df[\"Inhabitants Country in Mio\"] = [67.22, 67.39, 47.35]\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d68cf57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# it makes sense to give column names without spaces, so you can do:\n",
    "df.Capital  # this returns a pandas Series with name Capital!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5c4dbd8",
   "metadata": {},
   "source": [
    "We can also transform the above bird pandas series into a data frame. The Series name turns into the column name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95acfdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data frames and pandas series are not the same thing\n",
    "birds_df = pd.DataFrame(observed_birds)\n",
    "# Note the column name\n",
    "birds_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da037bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can change the column name with function rename():\n",
    "birds_df =birds_df.rename(columns={\"birds\":\"bird names\"}) # the same works with index\n",
    "birds_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35e4a03d",
   "metadata": {},
   "source": [
    "Back to the countries dataframe..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a96885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column's names\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deab86ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# row indexes names\n",
    "df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a05cc17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can also create a single-column DataFrame from a list (This is not a Pandas Series!)\n",
    "df = pd.DataFrame( [\"UK\", \"France\", \"Spain\"], columns = [\"Country\"])  \n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5daa2ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or start from a python dictionary with lists as values (must be of same length).\n",
    "country_dict = { \"Country\" :            [\"UK\",     \"France\", \"Spain\"],\n",
    "                 \"Capital\":            [\"London\", \"Paris\", \"Madrid\"],\n",
    "                 \"Inhabitants Country in Mio\": [67.22, 67.39, 47.35]}\n",
    "# write DataFrame to file, but without the index\n",
    "pd.DataFrame(country_dict).to_csv(data_dir + \"countries.csv\", index = False)\n",
    "# print inline\n",
    "country_df = pd.DataFrame(country_dict) # in jupyter, we just write the name of the dataFrame into the last line to show it nicely.\n",
    "# in a *.py file (in a script)\n",
    "\n",
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad1262a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you pass a dictionary with scalars instead of lists, \n",
    "# you have to tell pandas how to interpret that (by adding items())\n",
    "fruit_colors = {\"banana\": \"yellow\",\n",
    "                \"apple\" : \"green\",\n",
    "                \"orange\": \"orange\",\n",
    "                \"cherry\": \"red\",\n",
    "                \"berry\" : \"black\",\n",
    "                \"hammer\": \"grey\"\n",
    "               }\n",
    "fruit_df = pd.DataFrame(fruit_colors.items(), \n",
    "                        columns=[\"fruit\", \"color\"])\n",
    "fruit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d9b7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# you might want to have fruit as the index\n",
    "fruit_df = fruit_df.set_index(\"fruit\")\n",
    "fruit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ac0c288",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then you can access values by column + index\n",
    "fruit_df.color.apple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d9531f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hammer is not a fruit, so we just drop it from the data frame\n",
    "fruit_df = fruit_df.drop(\"hammer\")\n",
    "fruit_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac2db9da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# or you might regret setting \"fruits\" as index\n",
    "fruit_df = fruit_df.reset_index()\n",
    "fruit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c5e1756-0824-43a0-aa03-c7209756956d",
   "metadata": {},
   "source": [
    "#### Deprecated functions and handling exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d2edd1",
   "metadata": {},
   "source": [
    "The pandas function **append()** cannot be called anymore because it is deprecated since version 1.4.0. Below you'll see how to use **concat()** instead. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760eeecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    fruit_df.append({\"fruit\":\"plum\", \"color\":\"lila\"}, ignore_index=True)\n",
    "except Exception as e:\n",
    "     print(type(e), e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7259f6da-07f5-4e94-ae1c-84424c101a9c",
   "metadata": {},
   "source": [
    "We use the `try/except` block to handle exceptions.\n",
    "\n",
    "- The `try` block lets you test a block of code for errors.\n",
    "- The `except` block lets you handle the error.\n",
    "\n",
    "In this case, we show the message of the Exception due to `append()` is deprecated\n",
    "\n",
    "As a developer, it is also possible to `raise` exceptions.\n",
    "\n",
    "Take a look at the Python [documentation](https://docs.python.org/3/tutorial/errors.html) for more information on this topic.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228d0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([fruit_df,\n",
    "           pd.DataFrame({\"plum\":\"lila\"}.items(), \n",
    "                        columns=[\"fruit\", \"color\"])\n",
    "          ], \n",
    "          ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1850299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove column \"color\" with function pop\n",
    "fruit_df.pop(\"color\")\n",
    "fruit_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb3381f",
   "metadata": {},
   "source": [
    "NOTE that the usage of <code>pop()</code> (for removing columns) is different from that of <code>drop()</code> (for deleting rows):\n",
    "\n",
    "    fruit_df = fruit_df.drop(\"hammer\")\n",
    "    fruit_df  \n",
    "vs\n",
    "    \n",
    "    fruit_df.pop(\"color\")\n",
    "    fruit_df\n",
    "    \n",
    "For more on <code>pop()</code> see https://www.geeksforgeeks.org/python-pandas-dataframe-pop/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cec2003",
   "metadata": {},
   "outputs": [],
   "source": [
    "# And finally, and quite common, you can load excel sheets, csv files ( ..json, pickle, parquet..)\n",
    "# use help(pd.read_csv(\"countries.csv\") ) to know more\n",
    "country_df = pd.read_csv(data_dir + \"countries.csv\") \n",
    "# equivalent: pd.read_excel(\"countries.xlsx\")\n",
    "country_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2bfa40-397c-4e40-9c1c-9c2b13a9c98d",
   "metadata": {},
   "source": [
    "You can overwrite a column with a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59ef06f-932c-46cd-8dad-1c100831f439",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfa138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df.Capital = [\"LON\", \"PAR\", \"MAD\"] # you can replace complete columns like this\n",
    "country_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6aa8fed6-bc93-4af3-bbe1-62bb74c6d147",
   "metadata": {},
   "source": [
    "And you can output a subdataframe, consisting of several columns with their entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d81ba94",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_df[[\"Country\",\"Capital\"]] # returns a DataFrame, note the flipped order of columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59076b98",
   "metadata": {},
   "source": [
    "# TASK II: <a class=\"anchor\" id=\"task2\"></a>\n",
    "\n",
    "1. Add a new country. For instance, add Germany to the table with its capital (“Berlin”) and number of inhabitants (83.24 million).\n",
    "2. Add a new column. Create a new column called \"EU Member\" that indicates whether the country is part of the European Union.\n",
    "3. Update a value. Suppose France’s population has been updated to 68.0 million — modify the DataFrame accordingly.\n",
    "4. Sort the DataFrame. Sort all rows by the number of inhabitants, in descending order.\n",
    "5. Save your results. Write the final table to a file called updated_countries.csv (without including the index)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ef40c32-3a35-4625-88a0-3f18bbf6b761",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### solution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6769a",
   "metadata": {},
   "source": [
    "### 4.2. Operations on DataFrames <a class=\"anchor\" id=\"4.2\"></a>\n",
    "\n",
    "#### 4.2.1. Selecting data <a class=\"anchor\" id=\"4.2.1\"></a>\n",
    "\n",
    "We start from this dataset from Kaggle with data from IMDB https://www.kaggle.com/datasets/omarhanyy/imdb-top-1000/discussion/393097\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c265abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv(data_dir+\"imdb/imdb_top_1000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf640ca",
   "metadata": {},
   "source": [
    "You already know how to access columns and rows: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e4dd84-3115-4a82-903a-63f264841cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c258b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb[\"Series_Title\"] # returns a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260179ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.Series_Title # same thing; therefore: try to avoid using spaces in your column names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a374e7e4",
   "metadata": {},
   "source": [
    "#### 4.2.2. Slicing data frames <a class=\"anchor\" id=\"4.2.2\"></a>\n",
    "Slicing means to output one or several columns or rows. \n",
    "Slices can be either accessed by label with loc or by index with iloc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d0fa54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# original data frame at this point, before slicing: \n",
    "df_imdb.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d9ff8e7",
   "metadata": {},
   "source": [
    "#### 4.2.2.1. Slicing by label with **loc** <a class=\"anchor\" id=\"4.2.2.1\"></a>\n",
    "To change individual fields of the dataframe you need to use loc (by label) or iloc (by position).\n",
    "With indexing, your output is the value of the field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "140886fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# syntax: df.loc[row_indexer,column_indexer]\n",
    "df_imdb.loc[2, \"Series_Title\"] # the output is the column value of the row with index 2 and column Series_Title "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7603ec9a",
   "metadata": {},
   "source": [
    "Note that in the above example, 2 means the label and not the position of the respective row!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9248416",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.loc[2] # the output is the row with index 2 as pandas series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fe78c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.loc[:, \"Series_Title\"] # the output is the column Series_Title as pandas series"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36df244c",
   "metadata": {},
   "source": [
    "#### 4.2.2.2.  Slicing by position with **iloc** <a class=\"anchor\" id=\"4.2.2.2\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af95aee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.iloc[1, 2] # the output is the column value of the row with position 1 \n",
    "                   # (note that python always counts from 0) and column with position 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18a64fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.iloc[1, 1: 5] # "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47a68f5",
   "metadata": {},
   "source": [
    "### 4.2.3. Filtering <a class=\"anchor\" id=\"4.2.3\"></a>\n",
    "\n",
    "Pandas DataFrames (and Series) can be filtered by using **boolean expressions**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1295168",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb[df_imdb[\"Director\"]==\"Francis Ford Coppola\"] # use Boolean expressions for picking a row/ several rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f44f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb[df_imdb[\"Director\"]==\"Francis Ford Coppola\"].Star1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ab444-7e0f-40fd-8145-e6f8ce4874fa",
   "metadata": {},
   "source": [
    "Lets show the series and films premired in 2020 onwards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4da005",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_imdb[df_imdb[\"Released_Year\"] > 2020] # Another boolean expression\n",
    "except Exception as e:\n",
    "     print(type(e), e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea18a888-962f-4492-8994-fd0321f2b3f6",
   "metadata": {},
   "source": [
    "The series in column Released_Year is not a integer, let's convert to int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3796854-d752-49ce-bfe2-88267f9690f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    df_imdb[\"Released_Year\"] = df_imdb[\"Released_Year\"].astype(int) \n",
    "except Exception as e:\n",
    "     print(type(e), e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85090e15-631e-4550-9e90-f1504ab83173",
   "metadata": {},
   "source": [
    "It's not possible to convert it to int(). This error is caused because we try to convert an string to int instead to a float. So let's convert to int and then to float.\n",
    "We will use the function **apply()** https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8809c2e7-318b-4d88-ae88-1dc1ef42e8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function we apply to the series\n",
    "def toInt(x, ):\n",
    "    try:\n",
    "        x = int(float(x)) # from string to float to int\n",
    "    except:\n",
    "        x = np.nan\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a9b14fe-e602-4408-8d4b-8eaad389840c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb['Released_Year'] = df_imdb['Released_Year'].apply(toInt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9a11114-372c-45c9-b6a1-82e497b58605",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb[df_imdb[\"Released_Year\"] >= 2020]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9708639",
   "metadata": {},
   "source": [
    "### 4.2.4. Transposing, Sorting, and Grouping <a class=\"anchor\" id=\"4.2.4\"></a>\n",
    "\n",
    "You might have noticed that it's so easy and quick to work with columns and rather cumbersome and slow to work with rows. You can switch roles by transposing the table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe379d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7323253",
   "metadata": {},
   "source": [
    "You can sort an index alphabetically..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf065cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.T.sort_index(axis=0, ascending=True) # try also: ascending = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fce334",
   "metadata": {},
   "source": [
    "... or sort rows by the values of a column, eg. countries by their number of inhabitants:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23ea0e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb.sort_values(by=\"Released_Year\", ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb7550f1",
   "metadata": {},
   "source": [
    "To show how to **group**, we will groub by director and count how many series has been included in the list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9b1c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb[[\"Director\", \"Series_Title\"]].groupby('Director').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8879f546-678b-4645-949b-5ce578f037ec",
   "metadata": {},
   "source": [
    "Now we check which directors have more than 10 productions in the list and we group by Star1 (the main character) to see which are the characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d8e610-054c-4056-abdb-042b73a42aee",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = df_imdb[[\"Director\", \"Series_Title\"]].groupby('Director').count()\n",
    "s[s.Series_Title > 10].index.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a624ad1-2bcb-463a-b89f-aa0d884a7ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb[df_imdb[\"Director\"] == s[s.Series_Title > 10].index.tolist()[0]][[\"Director\", \"Star1\"]].groupby('Star1').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31329719",
   "metadata": {},
   "source": [
    "# TASK III: <a class=\"anchor\" id=\"task3\"></a>\n",
    "\n",
    "1. Add one of your favorite films or series to this dataset, including the actual data from IMDB.\n",
    "2. Calculate the average IMDB rating for all the films directed by the same director and save the result in a new column.\n",
    "\n",
    "You might want to crate a copy of the current data frame, so you don't have to rerun the notebook over and over again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed30b16",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "df_imdb_copy = df_imdb.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb3ee43-96bb-4d1a-8625-cee77931a1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd32e4d1",
   "metadata": {},
   "source": [
    "## 5. Advanced operations <a class=\"anchor\" id=\"5\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f59683",
   "metadata": {},
   "source": [
    "### MultiIndexing and Hierarchical Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51ac84e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a MultiIndex DataFrame\n",
    "arrays = [\n",
    "    ['Barcelona', 'Barcelona', 'Madrid', 'Madrid', 'Valencia', 'Valencia'],\n",
    "    ['2024', '2025', '2024', '2025', '2024', '2025']\n",
    "]\n",
    "index = pd.MultiIndex.from_arrays(arrays, names=('City', 'Year'))\n",
    "data = {'Population': [1.6, 1.62, 3.2, 3.25, 0.8, 0.83],\n",
    "        'GDP': [240, 250, 390, 410, 150, 155],\n",
    "        'Unemployment': [8.5, 8.3, 10.2, 9.8, 11.1, 10.9]}\n",
    "\n",
    "df_multi = pd.DataFrame(data, index=index)\n",
    "display(df_multi)\n",
    "\n",
    "# Accessing elements\n",
    "df_multi.loc['Barcelona']\n",
    "df_multi.xs('2025', level='Year')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad3146c1",
   "metadata": {},
   "source": [
    "### Aggregation across the first level (City)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8198d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate all years for each city\n",
    "agg_city = df_multi.groupby(level='City').agg({\n",
    "    'Population': ['mean', 'std', 'min', 'max'],\n",
    "    'Unemployment': ['min', 'max'],\n",
    "\n",
    "})\n",
    "agg_city"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a4f8ad",
   "metadata": {},
   "source": [
    "### Aggregation across both levels with custom functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e72f143",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom lambda and named aggregation\n",
    "agg_custom = (\n",
    "    df_multi.groupby(level=['City'])\n",
    "    .agg(\n",
    "        pop_growth=('Population', lambda x: (x.max() - x.min()) if len(x) > 1 else x.iloc[0]),\n",
    "        gdp_per_capita=('GDP', lambda x: x.mean() * 1000),  # just example scaling\n",
    "        mean_unemployment=('Unemployment', 'mean')\n",
    "    )\n",
    ")\n",
    "agg_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542a9273",
   "metadata": {},
   "outputs": [],
   "source": [
    "def growth_rate(series):\n",
    "    \"\"\"Compute relative growth rate (%) between first and last observation.\"\"\"\n",
    "    if len(series) < 2:\n",
    "        return 0\n",
    "    return (series.iloc[-1] - series.iloc[0]) / series.iloc[0] * 100\n",
    "\n",
    "def weighted_unemployment(df):\n",
    "    \"\"\"Compute GDP-weighted mean unemployment for a given group.\"\"\"\n",
    "    total_gdp = df['GDP'].sum()\n",
    "    return (df['Unemployment'] * df['GDP']).sum() / total_gdp if total_gdp > 0 else None\n",
    "\n",
    "# Apply custom functions via .agg()\n",
    "results = (\n",
    "    df_multi.groupby(level='City')\n",
    "    .apply(lambda x: pd.Series({\n",
    "        'Population growth (%)': growth_rate(x['Population']),\n",
    "        #'GDP growth (%)': growth_rate(x['GDP']),\n",
    "        'GDP-weighted unemployment': weighted_unemployment(x),\n",
    "        #'Population CV': coefficient_of_variation(x['Population'])\n",
    "    }))\n",
    ")\n",
    "\n",
    "display(results.round(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0313e60b",
   "metadata": {},
   "source": [
    "### Combining aggregation with transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2a577f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column of mean population per city (same shape as df)\n",
    "df_multi['Population_mean_city'] = df_multi.groupby(level='City')['Population'].transform('mean')\n",
    "df_multi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf71ee24",
   "metadata": {},
   "source": [
    "# TASK IV: <a class=\"anchor\" id=\"task4\"></a>\n",
    "\n",
    "Advanced GroupBy and custom aggregations with IMDb dataset\n",
    "\n",
    "1. Clean and process the dataset\n",
    "2. Apply custom aggregation functions to grouped data.  \n",
    "3. Derive genre-based indicators (e.g. weighted ratings, revenue efficiency).  \n",
    "4. Communicate insights through tables and plots.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78ba54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imdb = pd.read_csv(data_dir+\"imdb/imdb_top_1000.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00e397b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## solution\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a102093",
   "metadata": {},
   "source": [
    "## 6. Profiling <a class=\"anchor\" id=\"6\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a12409a-8090-4dda-90a9-59c620673f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ydata_profiling import ProfileReport\n",
    "\n",
    "profile = ProfileReport(df_imdb, title=\"Profiling Report\")\n",
    "profile"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67dccfec-2c96-4697-ac17-ef726662f5c5",
   "metadata": {},
   "source": [
    "## 7. Remarks <a class=\"anchor\" id=\"7\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62247334-b032-4563-92f9-c48d3529a19d",
   "metadata": {},
   "source": [
    "1. Use tab completion in pandas: start to write df.pl and fill by pressing TAB to complete, e.g. to df.plot()\n",
    "2. Depending on what we find in the databases that you chose, we might have to deal with Missing Data https://pandas.pydata.org/pandas-docs/stable/user_guide/missing_data.html#missing-data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e849be9f-89dd-4d4d-aa0a-bb0f17e72007",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "avbd",
   "language": "python",
   "name": "avbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
